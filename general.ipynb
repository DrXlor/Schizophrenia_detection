{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "r_s = 42\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_x = pd.read_pickle(\"../../BIO_Ml/Schizophrenia/one_by_one/mvals_train_val.pkl\")\n",
    "df_y = pd.read_pickle(\"../../BIO_Ml/Schizophrenia/one_by_one/pheno_train_val.pkl\")[\"Status\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df_x.head())\n",
    "df_y = LabelEncoder().fit_transform(df_y)\n",
    "print(df_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "start = time.time()\n",
    "selector_k = SelectKBest(score_func=f_classif, k=100)\n",
    "fit = selector_k.fit(df_x, df_y)\n",
    "cols = selector_k.get_support(indices=True)\n",
    "df_x = df_x.iloc[:, cols]\n",
    "\n",
    "model = SVC(kernel=\"linear\",\n",
    "            C=1.4,\n",
    "            random_state=r_s)\n",
    "model.fit(df_x, df_y)\n",
    "model.predict(df_x)\n",
    "\n",
    "finish = time.time()\n",
    "print(finish - start)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=r_s,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=df_y)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "start = time.time()\n",
    "kbest = SelectKBest()\n",
    "\n",
    "pipeline_svm = Pipeline([('kbest', kbest), ('svm', SVC(random_state=r_s))])\n",
    "\n",
    "svm_grid_params = {'kbest__score_func': ('f_classif', 'mutual_info_classif'),\n",
    "                   'kbest__k': [30, 100, 120],\n",
    "                   'svm__kernel': ('linear', 'poly'),\n",
    "                   'svm__C': [1.3, 1.4, 1.5]}\n",
    "\n",
    "clf_1 = GridSearchCV(pipeline_svm,\n",
    "                     svm_grid_params,\n",
    "                     refit=True,\n",
    "                     scoring=\"accuracy\",\n",
    "                     verbose=3,\n",
    "                     cv=2)\n",
    "clf_1.fit(df_x, df_y)\n",
    "print(\n",
    "    f\"The best SVC variant is {clf_1.best_estimator_} with parameters {clf_1.best_params_} and its accu score = {clf_1.score(df_x, df_y)}\")\n",
    "finish = time.time()\n",
    "print(finish - start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "pipeline_catboost = Pipeline([('kbest', kbest), ('catboost', CatBoostClassifier(silent=True, random_state=r_s))])\n",
    "\n",
    "cat_grid_params = {'kbest__score_func': ('f_classif', 'mutual_info_classif'),\n",
    "                   'kbest__k': [30, 100, 120],\n",
    "                   'catboost__loss_function': ('logloss', 'CrossEntropy'),\n",
    "                   'catboost__depth': [4, 6, 8],\n",
    "                   'catboost__l2_leaf_reg': [3, 5, 7, 15, 20]}\n",
    "\n",
    "clf_2 = GridSearchCV(pipeline_catboost,\n",
    "                     cat_grid_params,\n",
    "                     refit=True,\n",
    "                     scoring=\"accuracy\",\n",
    "                     n_jobs=2,\n",
    "                     verbose=3)\n",
    "clf_2.fit(df_x, df_y)\n",
    "print(\n",
    "    f\"The best Catboost variant model is {clf_2.best_estimator_} with parameters {clf_2.best_params_} and its accu score = {clf_2.score(df_x, df_y)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "\n",
    "pipeline_ada = Pipeline(\n",
    "    [('kbest', kbest), ('ada', AdaBoostClassifier(random_state=r_s, base_estimator=RandomForestClassifier()))])\n",
    "\n",
    "ada_grid_params = {'kbest__score_func': ('f_classif', 'mutual_info_classif'),\n",
    "                   'kbest__k': [30, 100, 120],\n",
    "                   'ada__n_estimators': [25, 50, 100],\n",
    "                   'ada__learning_rate': [0.25, 0.5, 1, 1.5],\n",
    "                   'ada__algorithm': ('SAMME', 'SAMME.R')}\n",
    "\n",
    "clf_3 = GridSearchCV(pipeline_ada,\n",
    "                     ada_grid_params,\n",
    "                     refit=True,\n",
    "                     scoring=\"accuracy\",\n",
    "                     n_jobs=2,\n",
    "                     verbose=3)\n",
    "clf_3.fit(df_x, df_y)\n",
    "print(\n",
    "    f\"The best AdaBoost variant model is {clf_3.best_estimator_} with parameters {clf_3.best_params_} and its accu score = {clf_3.score(df_x, df_y)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# {'algorithm': 'SAMME', 'learning_rate': 0.25, 'n_estimators': 25} and its accu score = 1.0\n",
    "classifier = AdaBoostClassifier(algorithm='SAMME',\n",
    "                                learning_rate=0.25,\n",
    "                                n_estimators=25,\n",
    "                                random_state=r_s,\n",
    "                                base_estimator=RandomForestClassifier())\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# {'depth': 4, 'l2_leaf_reg': 15, 'loss_function': 'CrossEntropy'}\n",
    "\"\"\"\n",
    "classifier = CatBoostClassifier(depth=4, l2_leaf_reg=15,\n",
    "                                loss_function='CrossEntropy',\n",
    "                                silent=True)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}